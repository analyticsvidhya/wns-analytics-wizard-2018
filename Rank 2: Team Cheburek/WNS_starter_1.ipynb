{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "from scipy.optimize import fmin\n",
    "from pylab import rcParams\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "rcParams['figure.figsize'] = 8, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, log_loss, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "from eli5.permutation_importance import get_score_importances as importances\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainTestHelper(object):\n",
    "    def __init__(self):\n",
    "        self.ntrain = None\n",
    "\n",
    "    def combine(self, train, test):\n",
    "        self.ntrain = train.shape[0]\n",
    "        if isinstance(train, np.ndarray):\n",
    "            return np.row_stack((train, test))\n",
    "        else:\n",
    "            return train.append(test).reset_index(drop=True)\n",
    "\n",
    "    def split(self, train_test):\n",
    "        if self.ntrain is None:\n",
    "            return None\n",
    "        if isinstance(train_test, np.ndarray):\n",
    "            train = train_test[:self.ntrain, :]\n",
    "            test = train_test[self.ntrain:, :]\n",
    "        else:\n",
    "            train = train_test.iloc[:self.ntrain, :].copy().reset_index(drop=True)\n",
    "            test = train_test.iloc[self.ntrain:, :].copy().reset_index(drop=True)\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LGBWrapper(object):\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        _X = lgb.Dataset(X, label=y)\n",
    "        self.model = lgb.train(self.params, _X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof_pred(model, X, y, folds):   \n",
    "    cvpred = np.zeros(X.shape[0])\n",
    "    for tr, te in tqdm_notebook(folds.split(X, y)):\n",
    "        X_tr, X_te = X.loc[tr], X.loc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        cvpred[te] = model.predict(X_te)\n",
    "    return cvpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just without tqdm\n",
    "def get_oof_pred2(model, X, y, folds):   \n",
    "    cvpred = np.zeros(X.shape[0])\n",
    "    for tr, te in folds.split(X, y):\n",
    "        X_tr, X_te = X.loc[tr], X.loc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        cvpred[te] = model.predict(X_te)\n",
    "    return cvpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(model, X, y, test, folds, metric, permute=False):\n",
    "    \n",
    "    def score(X, y):\n",
    "        y_pred = model.predict(X)\n",
    "        return metric(y, y_pred)\n",
    "    \n",
    "    cvpred = np.zeros(X.shape[0])\n",
    "    pred = np.zeros(test.shape[0])\n",
    "    global_imp = np.zeros(X.shape[1])\n",
    "    for tr, te in tqdm_notebook(folds.split(X, y)):\n",
    "        X_tr, X_te = X.loc[tr], X.loc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        cvpred[te] = model.predict(X_te)\n",
    "        pred += model.predict(test)\n",
    "        if permute is True:\n",
    "            base_score, local_imp = importances(score, X_te.values, y_te, n_iter=5, random_state=0)\n",
    "            global_imp += np.mean(local_imp, axis=0)\n",
    "    global_imp /= folds.get_n_splits() * (-1)\n",
    "    pred /= folds.get_n_splits()\n",
    "    return cvpred, pred, global_imp\n",
    "\n",
    "#compute permutation importance and run 'BACKWARD'\n",
    "class FeatureSelector(object):\n",
    "    def __init__(self, model, folds, metric):\n",
    "        self.model = model\n",
    "        self.folds = folds\n",
    "        self.metric = metric\n",
    "    \n",
    "    def fit(self, X, y, test):\n",
    "        cvpred, pred, importance = get_oof(self.model, X, y, test, self.folds, self.metric, permute=True)\n",
    "        base_score = self.metric(y, cvpred)\n",
    "        best_score = base_score\n",
    "        self.initial_importance = sorted(list(zip(importance, X.columns)), key=lambda x: x[0])\n",
    "        with open('WNS_selector_importance_raw', 'wb') as fp:\n",
    "            pickle.dump(dict(self.initial_importance), fp)\n",
    "        to_drop = []\n",
    "        print('Base score is:', base_score, '\\n')\n",
    "        for f in tqdm_notebook(self.initial_importance):\n",
    "            to_drop.append(f[1])\n",
    "            _X = X.drop(to_drop, axis=1)\n",
    "            _test = test.drop(to_drop, axis=1)\n",
    "            cvpred, pred, imp = get_oof(self.model, _X, y, _test, self.folds, self.metric)\n",
    "            if self.metric(y, cvpred) > best_score:\n",
    "                to_drop.pop()\n",
    "            else:\n",
    "                print('Feature ' + str(f[1]) + ' has been dropped >>')\n",
    "                print('Score: ' + str(best_score) + ' -> ' + str(self.metric(y, cvpred)))\n",
    "                best_score = self.metric(y, cvpred)\n",
    "                print()        \n",
    "        print('Final score: ', best_score)\n",
    "        self.weak_features = to_drop\n",
    "        self.strong_features = list(set(X.columns) - set(to_drop))\n",
    "        self.oof_train = cvpred\n",
    "        self.oof_test = pred\n",
    "        self.final_importance = imp\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof2(model, X, y, test, folds, metric, permute=False):\n",
    "    \n",
    "    def score(X, y):\n",
    "        y_pred = model.predict(X)\n",
    "        \n",
    "        def minus_f_score(cutoff):\n",
    "            if (cutoff < 0) or (cutoff > 1):\n",
    "                return np.inf\n",
    "            else:\n",
    "                return - 1* f1_score(y, 1 * (y_pred > cutoff))\n",
    "            \n",
    "        cutoff_null = [0]\n",
    "        cut_f_min = fmin(minus_f_score, cutoff_null, disp=False)\n",
    "        cut = cut_f_min[0]\n",
    "            \n",
    "        return f1_score(y, 1 * (y_pred > cut))\n",
    "    \n",
    "    cvpred = np.zeros(X.shape[0])\n",
    "    pred = np.zeros(test.shape[0])\n",
    "    global_imp = np.zeros(X.shape[1])\n",
    "    for tr, te in folds.split(X, y):\n",
    "        X_tr, X_te = X.loc[tr], X.loc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        cvpred[te] = model.predict(X_te)\n",
    "        pred += model.predict(test)\n",
    "        if permute is True:\n",
    "            base_score, local_imp = importances(score, X_te.values, y_te, n_iter=5, random_state=0)\n",
    "            global_imp += np.mean(local_imp, axis=0)\n",
    "    global_imp /= folds.get_n_splits()\n",
    "    pred /= folds.get_n_splits()\n",
    "    return cvpred, pred, global_imp\n",
    "# Same, but score is optimal f1-score for each prediction\n",
    "class FeatureSelector2(object):\n",
    "    def __init__(self, model, folds, metric):\n",
    "        self.model = model\n",
    "        self.folds = folds\n",
    "        self.metric = metric\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, test):\n",
    "        def score2(y, y_pred):\n",
    "        \n",
    "            def minus_f_score(cutoff):\n",
    "                if (cutoff < 0) or (cutoff > 1):\n",
    "                    return np.inf\n",
    "                else:\n",
    "                    return - 1* f1_score(y, 1 * (y_pred > cutoff))\n",
    "\n",
    "            cutoff_null = [0]\n",
    "            cut_f_min = fmin(minus_f_score, cutoff_null, disp=False)\n",
    "            cut = cut_f_min[0]\n",
    "\n",
    "            return f1_score(y, 1 * (y_pred > cut))\n",
    "            \n",
    "        cvpred, pred, importance = get_oof2(self.model, X, y, test, self.folds, self.metric, permute=True)\n",
    "        base_score = score2(y, cvpred)\n",
    "        best_score = base_score\n",
    "        self.initial_importance = sorted(list(zip(importance, X.columns)), key=lambda x: x[0])\n",
    "        to_drop = []\n",
    "        print('Base score is:', base_score, '\\n')\n",
    "        for f in tqdm_notebook(self.initial_importance):\n",
    "            to_drop.append(f[1])\n",
    "            _X = X.drop(to_drop, axis=1)\n",
    "            _test = test.drop(to_drop, axis=1)\n",
    "            cvpred, pred, imp = get_oof2(self.model, _X, y, _test, self.folds, self.metric)\n",
    "            if score2(y, cvpred) <= best_score:\n",
    "                to_drop.pop()\n",
    "            else:\n",
    "                print('Feature ' + str(f[1]) + ' has been dropped >>')\n",
    "                print('Score: ' + str(best_score) + ' -> ' + str(score2(y, cvpred)))\n",
    "                best_score = score2(y, cvpred)\n",
    "                print()        \n",
    "        print('Final score: ', best_score)\n",
    "        self.weak_features = to_drop\n",
    "        self.strong_features = list(set(X.columns) - set(to_drop))\n",
    "        self.oof_train = cvpred\n",
    "        self.oof_test = pred\n",
    "        self.final_importance = imp\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history_a( M_train_history):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=[6,6])\n",
    "    \n",
    "    plt.title('MSE Loss')\n",
    "    plt.plot(M_train_history, label='MSE', zorder=1, c='lightseagreen')\n",
    "    plt.xlabel('Iteration')\n",
    "    \n",
    "    plt.legend   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches_a(inputs,  batchsize, shuffle=False):             \n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_LZdllcl.xls')\n",
    "test = pd.read_csv('test_2umaH9m.xls')\n",
    "sub = pd.read_csv('sample_submission_M0L0uXE.xls')\n",
    "del train['employee_id'], test['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (54808, 13)\n",
      "Test shape: (23490, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['is_promoted']\n",
    "del train['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_no_feat = pd.read_csv('train_LZdllcl.xls')\n",
    "test_no_feat = pd.read_csv('test_2umaH9m.xls')\n",
    "del train_no_feat['is_promoted']\n",
    "del train_no_feat['employee_id']\n",
    "del test_no_feat['employee_id']\n",
    "\n",
    "helper = TrainTestHelper()\n",
    "data_no_feat = helper.combine(train_no_feat, test_no_feat)\n",
    "\n",
    "to_cat = ['department',\n",
    "          'region',\n",
    "          'gender',\n",
    "          'recruitment_channel']\n",
    "for c in to_cat:\n",
    "    data_no_feat[c] = pd.factorize(data_no_feat[c])[0]\n",
    "    \n",
    "ed_dict = {'Below Secondary': 0, 'Bachelor\\'s': 1, 'Master\\'s & above': 2}\n",
    "data_no_feat['education'] = data_no_feat['education'].map(ed_dict)\n",
    "train_no_feat, test_no_feat = helper.split(data_no_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = TrainTestHelper()\n",
    "data = helper.combine(train, test)\n",
    "\n",
    "to_cat = ['department',\n",
    "          'region',\n",
    "          'gender',\n",
    "          'recruitment_channel']\n",
    "for c in to_cat:\n",
    "    data[c] = pd.factorize(data[c])[0]\n",
    "    \n",
    "ed_dict = {'Below Secondary': 0, 'Bachelor\\'s': 1, 'Master\\'s & above': 2}\n",
    "data['education'] = data['education'].map(ed_dict)\n",
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont = ['avg_training_score', 'age' , 'education', 'length_of_service', 'previous_year_rating', 'no_of_trainings']\n",
    "cat = ['department', 'region', 'education', 'gender', 'recruitment_channel', 'no_of_trainings',\n",
    "       'KPIs_met >80%', 'awards_won?']\n",
    "binary = ['gender', 'KPIs_met >80%', 'awards_won?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for continuous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeaa40bb22f4bc59ba489a167ab74a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc0671c06ed441f9265334ab7a46a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f356defd184640588b328ffb3bc06119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41b5686ff224c30b461ad60f335cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea75b06aaa3440168d134150d991fa42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c484162fc2a4f66a8056d7e009338c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca8ed42fdfc4a6d930e55bc4f3ce9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_knn = copy.deepcopy(data)\n",
    "for feat in tqdm_notebook(cont):\n",
    "    X_knn = data_knn.drop(feat, axis=1)\n",
    "    y_knn = data_knn[feat]\n",
    "    for k in tqdm_notebook([5, 10, 50, 200, 1000]):\n",
    "        knn = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "        knn.fit(X_knn, y_knn)\n",
    "        pred_knn = knn.predict(X_knn)\n",
    "        data['dist_'+feat+'_from_'+str(k)+'_nearest_neighbors'] = y_knn-pred_knn\n",
    "        data[feat+'_divided_by_'+str(k)+'_nearest_neighbors'] = y_knn/pred_knn\n",
    "        data[feat+'_'+str(k)+'_nearest_neighbors'] = pred_knn\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN for categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0f5344fb9c468fb2190c509f2e80fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89399b30b76a4bde9ef4f51ee9012ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba846ee69eae47bf9f77f02335c258c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab5e9d126a241098d8092ec9bc1bc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd6847fac3f416b8fb7a89e345ee212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad676dc0299a478e80a4c347c45b515a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0af7d4c326473ea9b8f8e5f9e61529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121ceebb34094768948f39e700191e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c81f28e727f4678b03a03243e5b4547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for feat in tqdm_notebook(cat):\n",
    "    X_knn = data_knn.drop(feat, axis=1)\n",
    "    y_knn = data_knn[feat].factorize()[0]\n",
    "    for k in tqdm_notebook([5, 10, 50, 200, 1000]):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "        knn.fit(X_knn, y_knn)\n",
    "        pred_knn = knn.predict(X_knn)\n",
    "        pr = knn.predict_proba(X_knn)\n",
    "        prob_of_curr_class = np.array([pr[n, j] for n , j in enumerate(y_knn)])\n",
    "        data['Is_same_'+feat+'_from_'+str(k)+'_nearest_neighbors'] = (y_knn == pred_knn)\n",
    "        data['most_likelihood_class_'+feat+'_from_'+str(k)+'_nearest_neighbors'] = pred_knn\n",
    "        data['prob_of_most_likelihood_class_'+feat+'_from_'+str(k)+'_nearest_neighbors'] = pr.max(axis=1)\n",
    "        data['prob_of_'+feat+'_'+str(k)+'_nearest_neighbors'] = prob_of_curr_class\n",
    "        data['dist_to_most_likelihood_class_'+feat+'_'+str(k)+'_nearest_neighbors'] = pr.max(axis=1) -\\\n",
    "        prob_of_curr_class\n",
    "        try:\n",
    "            data['dist_from_least_likelihood_nonzero_class_'+feat+'_'+str(k)+'_nearest_neighbors'] = prob_of_curr_class -\\\n",
    "            np.array([i[i>0].min() for i in pr])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_knn_feat = data[data.columns[12:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_knn_feat.to_csv('data_knn_feat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = TrainTestHelper()\n",
    "data = helper.combine(train, test)\n",
    "\n",
    "to_cat = ['department',\n",
    "          'region',\n",
    "          'gender',\n",
    "          'recruitment_channel']\n",
    "for c in to_cat:\n",
    "    data[c] = pd.factorize(data[c])[0]\n",
    "    \n",
    "ed_dict = {'Below Secondary': 0, 'Bachelor\\'s': 1, 'Master\\'s & above': 2}\n",
    "data['education'] = data['education'].map(ed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data, data_knn_feat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect (1st and 2nd order) between binary and categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a22300dce63489dad909f73e474f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90055efa0aec491980556d752a874077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bf164c34a44063af2cca17d8883f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for bin_i in tqdm_notebook(binary):\n",
    "    for cat_name in cat:\n",
    "        if cat_name != bin_i:\n",
    "            data[cat_name+'_intersect_'+bin_i] = data[cat_name]*data[bin_i]\n",
    "for_dr = []            \n",
    "for bin_i in tqdm_notebook(binary):\n",
    "    for_dr.append(bin_i)\n",
    "    for bin_j in list(set(binary) - set(for_dr)):\n",
    "        for cat_name in cat:\n",
    "            if bin_i != bin_j:\n",
    "                if cat_name != bin_i:\n",
    "                    data[cat_name+'_intersect_'+bin_i+'_'+bin_j] = data[cat_name]*data[bin_i]*data[bin_j]\n",
    "                    \n",
    "for cat_name in tqdm_notebook(cat):\n",
    "        if cat_name not in binary:\n",
    "            data[cat_name+'_intersect_all_binary'] = data[cat_name]*data['gender']*data['KPIs_met >80%']*data['awards_won?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat2 = cat + list(data.columns[342:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple interaction among continuous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cont:\n",
    "    for j in cont:\n",
    "        if i != j:\n",
    "            data[i+'_multiplied_by_'+j] = data[i]*data[j]\n",
    "            try:\n",
    "                data[i+'_divided_by_'+j] = data[i]/data[j]\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some monotonical transformations of continuous features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for columns in cont:\n",
    "    data['log_'+columns] = np.log1p(data[columns])\n",
    "    data['exp_'+columns] = np.expm1(data[columns])\n",
    "    data['power_2_'+columns] = data[columns] ** 2\n",
    "    data['power_075_'+columns] = data[columns] ** 0.75\n",
    "    data['power_05_'+columns] = data[columns] ** 0.5\n",
    "    data['power_025_'+columns] = data[columns] ** 0.25\n",
    "    data['power_01_'+columns] = data[columns] ** 0.1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregates and statistics of continuous features for given level of categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f499c0a705484c81a337b92cebf5c336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b499eb12e6b48b4888847f56156d403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e241bf6606394013ab17ff7e6e1f559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c26b8c433644a187e4364ce3852036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225449f707d94868ad83992c7ac1f31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b576c72215d2493ba7eb32b68af00c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f646a85cf074b2fbcb5d39267e8ec2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for cont_name in tqdm_notebook(cont):\n",
    "    for cat_name in tqdm_notebook(cat2):\n",
    "        try:\n",
    "            data[cat_name+'_mean_'+cont_name] = data[cat_name].map(dict(data.groupby(cat_name).mean()[cont_name]))\n",
    "            data[cat_name+'_max_'+cont_name] = data[cat_name].map(dict(data.groupby(cat_name).max()[cont_name]))\n",
    "            data[cat_name+'_min_'+cont_name] = data[cat_name].map(dict(data.groupby(cat_name).min()[cont_name]))\n",
    "            data[cat_name+'_sum_'+cont_name] = data[cat_name].map(dict(data.groupby(cat_name).sum()[cont_name]))\n",
    "            data[cat_name+'_count_'+cont_name] = data[cat_name].map(dict(data.groupby(cat_name).count()[cont_name]))\n",
    "\n",
    "            data[cat_name+'_divided_by_max_'+cont_name] = data[cont_name]/data[cat_name+'_max_'+cont_name]\n",
    "            data[cat_name+'_divided_by_mean_'+cont_name] = data[cont_name]/data[cat_name+'_mean_'+cont_name]\n",
    "            data[cat_name+'_divided_by_sum_'+cont_name] = data[cont_name]/data[cat_name+'_sum_'+cont_name]\n",
    "            data[cat_name+'_divided_by_count_'+cont_name] = data[cont_name]/data[cat_name+'_count_'+cont_name]\n",
    "\n",
    "            data[cat_name+'_normed_by_min_max_'+cont_name] = (data[cont_name] - data[cat_name+'_min_'+cont_name])/ \\\n",
    "            (data[cat_name+'_max_'+cont_name] - data[cat_name+'_min_'+cont_name])\n",
    "\n",
    "            data[cat_name+'_dist_from_min_'+cont_name] = (data[cont_name] - data[cat_name+'_min_'+cont_name])\n",
    "            data[cat_name+'_dist_to_max_'+cont_name] = (data[cat_name+'_max_'+cont_name] - data[cont_name])\n",
    "            data[cat_name+'_dist_from_mean_'+cont_name] = (data[cont_name] - data[cat_name+'_mean_'+cont_name])\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data_feat.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple reconstruction error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_knn)\n",
    "X_train = scaler.transform(data_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Autoencoder, self).__init__()    \n",
    "        self.fc1 = nn.Linear(int(X_train.shape[1]), int(X_train.shape[1]/2))\n",
    "        self.fc2 = nn.Linear(int(X_train.shape[1]/2), int(X_train.shape[1]/2))\n",
    "        self.fc3 = nn.Linear(int(X_train.shape[1]/2), int(X_train.shape[1]))       \n",
    "        \n",
    "    def forward(self, x1):\n",
    "        inputs = x1 \n",
    "        x = F.leaky_relu(self.fc1(inputs))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        output = F.sigmoid(self.fc3(x))\n",
    "        return output\n",
    "        \n",
    "    def get_error_mse(self, x):\n",
    "    \n",
    "        X_mb = Variable(torch.from_numpy(x)).type(torch.FloatTensor).cuda()        \n",
    "        auto = self.forward(X_mb)\n",
    "        output = torch.mean((X_mb - auto)**2, dim=1)\n",
    "        \n",
    "        return output.data.cpu().numpy()\n",
    "    \n",
    "    def get_error_mae(self, x):\n",
    "    \n",
    "        X_mb = Variable(torch.from_numpy(x)).type(torch.FloatTensor).cuda()        \n",
    "        auto = self.forward(X_mb)\n",
    "        output = torch.mean(torch.abs(X_mb - auto), dim=1)\n",
    "        \n",
    "        return output.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_a(model, opt, batchsize=200):\n",
    "    MSE_log =  []\n",
    "    for x_batch in iterate_minibatches_a(X_train, batchsize=batchsize, shuffle=True):\n",
    "        X_mb = Variable(torch.from_numpy(x_batch)).type(torch.FloatTensor).cuda()\n",
    "        A_solver = opt            \n",
    "        A_solver.zero_grad()\n",
    "        output = model(X_mb)\n",
    "        MSE_train_loss = torch.mean(( X_mb - output)**2)\n",
    "        MSE_train_loss.backward()\n",
    "        \n",
    "        A_solver.step()\n",
    "        MSE_loss = MSE_train_loss.cpu().data.numpy()\n",
    "        MSE_log.append(MSE_loss)\n",
    "        \n",
    "    return MSE_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, MSE loss: 0.018566854298114777\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAGHCAYAAABccIIuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14ba4ca1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.manual_seed(60)\n",
    "torch.manual_seed(60)\n",
    "\n",
    "MSE_loss_log = []\n",
    "\n",
    "batchsize = 200\n",
    "lr = 0.02\n",
    "\n",
    "\n",
    "Autoencoder_model = Autoencoder().cuda()\n",
    "\n",
    "opt = torch.optim.Adam(Autoencoder_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(2):\n",
    "    steps = X_train.shape[0]/batchsize\n",
    "\n",
    "    MSE_loss = train_a(Autoencoder_model, opt, batchsize=batchsize)\n",
    "\n",
    "    MSE_loss_log.extend(MSE_loss) \n",
    "    clear_output()\n",
    "    print('Epoch: {e}, MSE loss: {M1}'.format(e=epoch, M1=np.mean(MSE_loss)))\n",
    "    \n",
    "    plot_history_a( MSE_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['reconstruction_error_mse'] = Autoencoder_model.eval().get_error_mse(X_train)\n",
    "data['reconstruction_error_mae'] = Autoencoder_model.eval().get_error_mae(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('data_feat_with_re.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_feat_with_re.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = helper.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train\n",
    "del data_knn\n",
    "del data_knn_feat\n",
    "del X_knn\n",
    "del y_knn\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 4757)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=3, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167005e163d24091b3c3aa0b121c9cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imp_auc = []\n",
    "for col in tqdm_notebook(train.columns):\n",
    "    imp_auc.append([col , 2*np.abs(roc_auc_score(y, train[col].replace([np.inf, -np.inf], [np.NaN, np.NaN]).fillna(-1)))-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(imp_auc, columns=['Feature', 'Gini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>gender_intersect_KPIs_met &gt;80%_divided_by_coun...</td>\n",
       "      <td>0.468511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>KPIs_met &gt;80%_intersect_gender_KPIs_met &gt;80%_d...</td>\n",
       "      <td>0.468511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>region_intersect_KPIs_met &gt;80%_divided_by_coun...</td>\n",
       "      <td>0.474005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>region_intersect_KPIs_met &gt;80%_divided_by_sum_...</td>\n",
       "      <td>0.474302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>education_intersect_KPIs_met &gt;80%_divided_by_c...</td>\n",
       "      <td>0.507860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>education_intersect_KPIs_met &gt;80%_divided_by_s...</td>\n",
       "      <td>0.507860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>no_of_trainings_intersect_KPIs_met &gt;80%_divide...</td>\n",
       "      <td>0.528221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>no_of_trainings_intersect_KPIs_met &gt;80%_divide...</td>\n",
       "      <td>0.528329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>KPIs_met &gt;80%_divided_by_sum_avg_training_score</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>KPIs_met &gt;80%_divided_by_count_avg_training_score</td>\n",
       "      <td>0.545403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature      Gini\n",
       "733  gender_intersect_KPIs_met >80%_divided_by_coun...  0.468511\n",
       "940  KPIs_met >80%_intersect_gender_KPIs_met >80%_d...  0.468511\n",
       "707  region_intersect_KPIs_met >80%_divided_by_coun...  0.474005\n",
       "706  region_intersect_KPIs_met >80%_divided_by_sum_...  0.474302\n",
       "720  education_intersect_KPIs_met >80%_divided_by_c...  0.507860\n",
       "719  education_intersect_KPIs_met >80%_divided_by_s...  0.507860\n",
       "759  no_of_trainings_intersect_KPIs_met >80%_divide...  0.528221\n",
       "758  no_of_trainings_intersect_KPIs_met >80%_divide...  0.528329\n",
       "576    KPIs_met >80%_divided_by_sum_avg_training_score  0.544554\n",
       "577  KPIs_met >80%_divided_by_count_avg_training_score  0.545403"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Gini > 0.35 ].sort_values('Gini').iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_gini = df[df.Gini > 0.4 ].sort_values('Gini').Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_lbg = lgb.cv(nfold=2, shuffle=True,\n",
    "                metrics='log_loss', params=params2, seed=0, train_set=lgb.Dataset(train, label=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_lgb = m.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.array([train.columns, imp_lgb]).T, columns=['Feature', 'imp']).sort_values('imp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_dict = dict(np.array([imp_lgb + np.random.uniform(0,0.1, imp_lgb.shape), train.columns]).T)\n",
    "ar_imp = np.array(list(imp_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4757 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score: 0.17147941675925427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/4757 [00:02<32:41,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat reconstruction_error_mse was added. Base score: 0.16983953986001696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 6/4757 [00:04<55:22,  1.43it/s]\n",
      "Exception in thread Thread-54:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat region_mean_previous_year_rating was added. Base score: 0.16777816629767137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/4757 [00:11<1:39:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat avg_training_score_multiplied_by_previous_year_rating was added. Base score: 0.16394556153417378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/4757 [00:19<2:05:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat avg_training_score_50_nearest_neighbors was added. Base score: 0.16372975261980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/4757 [00:24<2:17:59,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat previous_year_rating_1000_nearest_neighbors was added. Base score: 0.16337398884069185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/4757 [00:48<2:53:22,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat dist_from_least_likelihood_nonzero_class_education_50_nearest_neighbors was added. Base score: 0.16331212043430388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 25/4757 [00:57<3:00:56,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_intersect_KPIs_met >80%_divided_by_count_previous_year_rating was added. Base score: 0.16324983606508922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 26/4757 [01:00<3:03:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat prob_of_KPIs_met >80%_1000_nearest_neighbors was added. Base score: 0.16300410168492674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 34/4757 [01:27<3:23:13,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat length_of_service_divided_by_10_nearest_neighbors was added. Base score: 0.16299938645307938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 48/4757 [02:18<3:46:57,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat region_mean_age was added. Base score: 0.16290384822618736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/4757 [02:30<3:50:51,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat department_intersect_KPIs_met >80%_divided_by_sum_previous_year_rating was added. Base score: 0.16272639210852405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 53/4757 [02:37<3:53:30,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat age_divided_by_5_nearest_neighbors was added. Base score: 0.16267482634147915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 54/4757 [02:41<3:54:48,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat prob_of_most_likelihood_class_recruitment_channel_from_50_nearest_neighbors was added. Base score: 0.16232515498231465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 114/4757 [06:53<4:40:54,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat prob_of_awards_won?_200_nearest_neighbors was added. Base score: 0.16205090249129173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 115/4757 [06:57<4:41:08,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat department_divided_by_max_no_of_trainings was added. Base score: 0.162019554791642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 119/4757 [07:15<4:42:49,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat dist_from_least_likelihood_nonzero_class_awards_won?_50_nearest_neighbors was added. Base score: 0.16187452772640312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 121/4757 [07:24<4:43:38,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat prob_of_most_likelihood_class_gender_from_10_nearest_neighbors was added. Base score: 0.16186105655919839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 124/4757 [07:37<4:45:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat education_divided_by_5_nearest_neighbors was added. Base score: 0.1616007244095151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 128/4757 [07:56<4:47:07,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat recruitment_channel_intersect_gender_KPIs_met >80%_divided_by_mean_previous_year_rating was added. Base score: 0.16145093533609864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 129/4757 [08:01<4:47:36,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_intersect_gender_divided_by_sum_age was added. Base score: 0.16129783409065765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 138/4757 [08:45<4:53:13,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat dist_from_least_likelihood_nonzero_class_awards_won?_200_nearest_neighbors was added. Base score: 0.16121040165459838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 150/4757 [09:48<5:01:01,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat previous_year_rating_divided_by_no_of_trainings was added. Base score: 0.16118146587996257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 390/4757 [30:55<5:46:22,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat most_likelihood_class_no_of_trainings_from_5_nearest_neighbors was added. Base score: 0.16111096951505416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 790/4757 [1:06:12<5:32:27,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat awards_won?_intersect_KPIs_met >80%_dist_to_max_previous_year_rating was added. Base score: 0.16110925307823945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 811/4757 [1:08:04<5:31:15,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_sum_length_of_service was added. Base score: 0.16110739052253567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 931/4757 [1:19:00<5:24:43,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_intersect_awards_won? was added. Base score: 0.16110738700659838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 1076/4757 [1:32:16<5:15:41,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat department_intersect_KPIs_met >80%_min_age was added. Base score: 0.16110728255413545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1622/4757 [2:23:18<4:36:58,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat region_intersect_all_binary_min_length_of_service was added. Base score: 0.16109529542439033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 1838/4757 [2:43:52<4:20:15,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat dist_to_most_likelihood_class_awards_won?_200_nearest_neighbors was added. Base score: 0.16109356950999537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 2267/4757 [3:25:03<3:45:14,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_intersect_gender_min_no_of_trainings was added. Base score: 0.16107215687197324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 2465/4757 [3:44:20<3:28:35,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat recruitment_channel_intersect_awards_won?_max_avg_training_score was added. Base score: 0.16104430259607022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 3532/4757 [5:30:03<1:54:28,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat no_of_trainings_intersect_gender_KPIs_met >80%_min_no_of_trainings was added. Base score: 0.16095980600371632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 4706/4757 [7:29:42<04:52,  5.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat region_intersect_awards_won?_min_previous_year_rating was added. Base score: 0.16093125608978612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4757/4757 [7:34:59<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# 'FORWARD'\n",
    "feat = []\n",
    "for i in tqdm(list(reversed([imp_dict.get(g) for g in np.sort(ar_imp)]))):\n",
    "    feat.append(i)\n",
    "    if len(feat)==5:\n",
    "        model = LGBWrapper(params2)\n",
    "        oof_pred = get_oof_pred2(model, train[feat], y, folds)\n",
    "        base_score = log_loss(y, oof_pred)\n",
    "        print('Base score: {bs}'.format(bs = base_score))\n",
    "    if len(feat)>5:\n",
    "        model = LGBWrapper(params2)\n",
    "        oof_pred = get_oof_pred2(model, train[feat], y, folds)\n",
    "        if log_loss(y, oof_pred) >= base_score:\n",
    "            feat.pop()\n",
    "        else:\n",
    "            base_score = log_loss(y, oof_pred)\n",
    "            print('feat {i} was added. Base score: {bs}'.format(i=i, bs = base_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('WNS_selector2_strong_feat', 'wb') as fp:\n",
    "    pickle.dump(feat, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('WNS_selector2_strong_feat', 'rb') as fp:\n",
    "    selector2_strong_feat = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 66)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[selector2_strong_feat+['reconstruction_error_mse', 'reconstruction_error_mae']+list(feat_gini)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_no_feat = pd.read_csv('train_LZdllcl.xls')\n",
    "test_no_feat = pd.read_csv('test_2umaH9m.xls')\n",
    "del train_no_feat['is_promoted']\n",
    "del train_no_feat['employee_id']\n",
    "del test_no_feat['employee_id']\n",
    "\n",
    "helper = TrainTestHelper()\n",
    "data_no_feat = helper.combine(train_no_feat, test_no_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_no_feat['department|training'] = data_no_feat['department'] + \\\n",
    "np.digitize(data_no_feat['avg_training_score'], [c * 10 for c in range(3, 11)]).astype(str)\n",
    "data_no_feat['kpi|training'] = data_no_feat['KPIs_met >80%'].astype(str) + \\\n",
    "np.digitize(data_no_feat['avg_training_score'], [c * 10 for c in range(3, 11)]).astype(str)\n",
    "data_no_feat['department|kpi'] = data_no_feat['department'] + data_no_feat['KPIs_met >80%'].astype(str)\n",
    "data_no_feat['kpi*rating'] = data_no_feat['KPIs_met >80%'] * data_no_feat['previous_year_rating']\n",
    "\n",
    "data_no_feat['mean_training_by_department'] = \\\n",
    "data_no_feat['department'].map(data_no_feat.groupby('department')['avg_training_score'].mean())\n",
    "data_no_feat['department_training_mean_ratio'] = data_no_feat['avg_training_score'] /\\\n",
    "data_no_feat['mean_training_by_department']\n",
    "\n",
    "data_no_feat['mean_rating_by_department'] =\\\n",
    "data_no_feat['department'].map(data_no_feat.groupby('department')['previous_year_rating'].mean())\n",
    "data_no_feat['department_rating_mean_ratio'] = data_no_feat['previous_year_rating'] / \\\n",
    "data_no_feat['mean_rating_by_department']\n",
    "\n",
    "data_no_feat['mean_kpi_by_department'] = \\\n",
    "data_no_feat['department'].map(data_no_feat.groupby('department')['KPIs_met >80%'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_cat = ['department',\n",
    "          'region',\n",
    "          'gender',\n",
    "          'recruitment_channel',\n",
    "          'department|training',\n",
    "          'department|kpi',\n",
    "          'kpi|training']\n",
    "for c in to_cat:\n",
    "    data_no_feat[c] = pd.factorize(data_no_feat[c])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed_dict = {'Below Secondary': 0, 'Bachelor\\'s': 1, 'Master\\'s & above': 2}\n",
    "data_no_feat['education'] = data_no_feat['education'].map(ed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_feat = pd.concat([data_no_feat,\n",
    "                       data[selector2_strong_feat+['reconstruction_error_mse',\n",
    "                                                   'reconstruction_error_mae']+list(feat_gini)]],\n",
    "                      axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = helper.split(data_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score is: 0.522699717095514 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f61d538726492db935eaa50332de30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-93:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Simakov\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature age_divided_by_5_nearest_neighbors has been dropped >>\n",
      "Score: 0.522699717095514 -> 0.5278491859468724\n",
      "\n",
      "Feature avg_training_score_50_nearest_neighbors has been dropped >>\n",
      "Score: 0.5278491859468724 -> 0.5288630525888873\n",
      "\n",
      "Feature KPIs_met >80%_divided_by_count_avg_training_score has been dropped >>\n",
      "Score: 0.5288630525888873 -> 0.53054705177692\n",
      "\n",
      "Feature most_likelihood_class_no_of_trainings_from_5_nearest_neighbors has been dropped >>\n",
      "Score: 0.53054705177692 -> 0.5306345733041576\n",
      "\n",
      "Feature region_intersect_all_binary_min_length_of_service has been dropped >>\n",
      "Score: 0.5306345733041576 -> 0.5324354040681694\n",
      "\n",
      "\n",
      "Final score:  0.5324354040681694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.FeatureSelector2 at 0x18e072041d0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'app': 'binary',\n",
    "          'metric': 'binary_logloss',\n",
    "          'n_jobs': -1}\n",
    "model = LGBWrapper(params)\n",
    "\n",
    "selector2 = FeatureSelector2(model=model, folds=folds, metric=f1_score)\n",
    "selector2.fit(train, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strong2 = selector2.strong_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[strong2].to_csv('train_strong2.csv', index=False)\n",
    "test[strong2].to_csv('test_strong2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l2 |   min_data_in_leaf |   num_leaves | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:661: UserWarning: silent keyword has been found in `params` and will be ignored. Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[33]\tcv_agg's binary_logloss: 0.163637 + 0.00416795\n",
      "    1 | 00m06s |   -0.16364 |             0.8300 |             0.9155 |      2.5222 |            94.4070 |      53.0765 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\tcv_agg's binary_logloss: 0.163326 + 0.00360989\n",
      "    2 | 00m04s |   -0.16333 |             0.8835 |             0.7029 |      1.2556 |            29.1696 |      56.2410 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\tcv_agg's binary_logloss: 0.163988 + 0.00415721\n",
      "    3 | 00m04s |   -0.16399 |             0.6443 |             0.6072 |      2.3892 |            67.1707 |      60.7279 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\tcv_agg's binary_logloss: 0.162661 + 0.00431696\n",
      "    4 | 00m05s |   -0.16266 |             0.6242 |             0.9050 |      3.9224 |            62.6990 |      39.1210 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\tcv_agg's binary_logloss: 0.163198 + 0.0031971\n",
      "    5 | 00m05s |   -0.16320 |             0.5661 |             0.8832 |      1.0144 |            37.3229 |      40.8386 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l2 |   min_data_in_leaf |   num_leaves | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tcv_agg's binary_logloss: 0.162722 + 0.00339757\n",
      "    6 | 00m17s |   -0.16272 |             0.9823 |             0.6659 |      4.9195 |             5.3555 |       4.5848 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.75390954e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tcv_agg's binary_logloss: 0.163045 + 0.00338051\n",
      "    7 | 00m16s |   -0.16304 |             0.9727 |             0.5677 |      4.2197 |            99.7256 |       4.1217 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tcv_agg's binary_logloss: 0.163237 + 0.00364654\n",
      "    8 | 00m20s |   -0.16324 |             0.5054 |             0.9748 |      4.6711 |             4.5596 |      60.8374 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[55]\tcv_agg's binary_logloss: 0.162148 + 0.00413083\n",
      "    9 | 00m16s |   -0.16215 |             0.9385 |             0.5004 |      4.9943 |             4.3040 |      35.8203 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00055515]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.43652903e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\tcv_agg's binary_logloss: 0.162237 + 0.00325827\n",
      "   10 | 00m17s |   -0.16224 |             0.9530 |             0.9125 |      4.9684 |            40.5585 |      28.5383 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.0002531]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.83898853e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[73]\tcv_agg's binary_logloss: 0.161822 + 0.00377025\n",
      "   11 | 00m18s |   -0.16182 |             0.9894 |             0.9061 |      4.9715 |             4.1518 |      33.6971 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00047004]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 47, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[60]\tcv_agg's binary_logloss: 0.162663 + 0.00399101\n",
      "   12 | 00m18s |   -0.16266 |             0.9859 |             0.9579 |      4.7804 |            75.3499 |      24.0500 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00214141]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00060125]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[55]\tcv_agg's binary_logloss: 0.162562 + 0.00380084\n",
      "   13 | 00m18s |   -0.16256 |             0.9392 |             0.9832 |      4.8580 |            99.8613 |      28.2812 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\tcv_agg's binary_logloss: 0.163331 + 0.0033968\n",
      "   14 | 00m19s |   -0.16333 |             0.8529 |             0.9479 |      4.9787 |            27.1419 |      47.3769 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00020779]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.8155011e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 65, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[38]\tcv_agg's binary_logloss: 0.16503 + 0.00414958\n",
      "   15 | 00m20s |   -0.16503 |             0.9587 |             0.7127 |      1.1582 |             4.1477 |      99.1917 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.63280817e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.44045223e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[30]\tcv_agg's binary_logloss: 0.166079 + 0.00486163\n",
      "   16 | 00m21s |   -0.16608 |             0.9482 |             0.7979 |      4.8941 |            99.8220 |      99.2862 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tcv_agg's binary_logloss: 0.162925 + 0.00386107\n",
      "   17 | 00m19s |   -0.16293 |             0.9825 |             0.8899 |      0.0806 |             4.0024 |      41.2340 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.51359262e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tcv_agg's binary_logloss: 0.16219 + 0.00363561\n",
      "   18 | 00m18s |   -0.16219 |             0.9737 |             0.8238 |      0.1605 |            99.1671 |      27.1985 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[28]\tcv_agg's binary_logloss: 0.166239 + 0.00450627\n",
      "   19 | 00m21s |   -0.16624 |             0.9227 |             0.9560 |      0.0017 |            55.3707 |      99.6492 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[174]\tcv_agg's binary_logloss: 0.162835 + 0.00317036\n",
      "   20 | 00m19s |   -0.16284 |             0.9561 |             0.9784 |      4.9982 |            43.9396 |       5.8450 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\tcv_agg's binary_logloss: 0.163368 + 0.0032589\n",
      "   21 | 00m18s |   -0.16337 |             0.9886 |             0.9767 |      0.2849 |            57.7767 |      37.0119 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\tcv_agg's binary_logloss: 0.168894 + 0.00533586\n",
      "   22 | 00m21s |   -0.16889 |             0.6042 |             0.9503 |      0.2304 |            99.7131 |      98.2750 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\tcv_agg's binary_logloss: 0.164116 + 0.00531026\n",
      "   23 | 00m19s |   -0.16412 |             0.5124 |             0.5845 |      4.9665 |            28.5906 |      91.6856 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\tcv_agg's binary_logloss: 0.161876 + 0.00330063\n",
      "   24 | 00m18s |   -0.16188 |             0.5371 |             0.9636 |      4.9599 |            18.4332 |      16.4692 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.02940428e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\tcv_agg's binary_logloss: 0.162593 + 0.00302485\n",
      "   25 | 00m18s |   -0.16259 |             0.5816 |             0.8488 |      0.0492 |             4.1189 |      16.7840 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[103]\tcv_agg's binary_logloss: 0.162338 + 0.0038232\n",
      "   26 | 00m19s |   -0.16234 |             0.5159 |             0.9875 |      0.0584 |            96.8695 |       8.5024 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00057801]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\tcv_agg's binary_logloss: 0.161479 + 0.00369242\n",
      "   27 | 00m19s |   -0.16148 |             0.5029 |             0.9895 |      4.8957 |             4.1755 |      18.6710 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tcv_agg's binary_logloss: 0.160978 + 0.00369574\n",
      "   28 | 00m17s |   -0.16098 |             0.5289 |             0.5021 |      1.3557 |            99.5338 |      19.3061 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[50]\tcv_agg's binary_logloss: 0.161551 + 0.00425826\n",
      "   29 | 00m17s |   -0.16155 |             0.5410 |             0.5010 |      2.4844 |            90.8435 |      28.4122 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tcv_agg's binary_logloss: 0.161319 + 0.00393223\n",
      "   30 | 00m17s |   -0.16132 |             0.5366 |             0.5501 |      4.8739 |            57.5756 |      19.5529 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[55]\tcv_agg's binary_logloss: 0.161395 + 0.00496376\n",
      "   31 | 00m17s |   -0.16139 |             0.5355 |             0.5256 |      0.4284 |            97.5177 |      21.8488 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00024833]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 67, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00214646]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00370693]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\tcv_agg's binary_logloss: 0.164839 + 0.00339705\n",
      "   32 | 00m19s |   -0.16484 |             0.5498 |             0.5228 |      4.9139 |            74.1656 |      99.4538 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00035805]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00457658]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00059156]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's binary_logloss: 0.161325 + 0.00382359\n",
      "   33 | 00m18s |   -0.16133 |             0.5066 |             0.5917 |      0.0914 |            47.9971 |      16.6303 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.41160563e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 8, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.01314188]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\tcv_agg's binary_logloss: 0.162567 + 0.00401241\n",
      "   34 | 00m20s |   -0.16257 |             0.5165 |             0.5042 |      4.4713 |            99.0988 |      43.8176 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\tcv_agg's binary_logloss: 0.162689 + 0.00419405\n",
      "   35 | 00m20s |   -0.16269 |             0.5055 |             0.5005 |      4.6555 |            85.0177 |      44.1787 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[33]\tcv_agg's binary_logloss: 0.164798 + 0.00520466\n",
      "   36 | 00m20s |   -0.16480 |             0.7533 |             0.5057 |      4.9790 |            99.3767 |      75.1109 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014261]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 82, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00112166]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00042552]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.002259]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 76, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\tcv_agg's binary_logloss: 0.16416 + 0.00401642\n",
      "   37 | 00m23s |   -0.16416 |             0.5182 |             0.8207 |      4.8134 |            46.1409 |      75.2318 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[68]\tcv_agg's binary_logloss: 0.161262 + 0.00384629\n",
      "   38 | 00m18s |   -0.16126 |             0.5514 |             0.6384 |      4.0635 |            38.4294 |      16.8110 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[56]\tcv_agg's binary_logloss: 0.161388 + 0.00409021\n",
      "   39 | 00m19s |   -0.16139 |             0.5013 |             0.6691 |      4.6144 |            49.8164 |      17.3487 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00056217]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 71, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011124]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00014649]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 71, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00228364]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[93]\tcv_agg's binary_logloss: 0.160715 + 0.00374309\n",
      "   40 | 00m20s |   -0.16072 |             0.9459 |             0.5005 |      0.0226 |            99.7803 |      13.9817 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00678123]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 63, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.17651653e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00018139]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.60626727e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011737]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 71, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[53]\tcv_agg's binary_logloss: 0.161362 + 0.0039804\n",
      "   41 | 00m19s |   -0.16136 |             0.9621 |             0.5206 |      0.2980 |            99.6111 |      17.0963 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010947]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 69, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\tcv_agg's binary_logloss: 0.165258 + 0.0037095\n",
      "   42 | 00m25s |   -0.16526 |             0.7390 |             0.9854 |      0.0128 |            12.9307 |      82.7291 | \n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[92]\tcv_agg's binary_logloss: 0.164161 + 0.00387717\n",
      "   43 | 00m18s |   -0.16416 |             0.5043 |             0.5339 |      0.0956 |            22.7229 |       4.2747 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simakov\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00026391]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-6401f4a289e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m                                                 })\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mlgbBO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    299\u001b[0m                             \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m                             **self._acqkw)\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;31m# Keep track of total number of iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\helpers.py\u001b[0m in \u001b[0;36macq_max\u001b[1;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[0;32m     58\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# Store it if better than previous minimum(maximum).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 450\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    451\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\helpers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[0;32m     58\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\helpers.py\u001b[0m in \u001b[0;36mutility\u001b[1;34m(self, x, gp, y_max)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ucb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ei'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\bayes_opt\\helpers.py\u001b[0m in \u001b[0;36m_ucb\u001b[1;34m(x, gp, kappa)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0my_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Predict based on GP posterior\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[0mK_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Line 4 (y_mean = f_star)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_train_mean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_mean\u001b[0m  \u001b[1;31m# undo normal.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1322\u001b[0m                     \"Gradient can only be evaluated when Y is None.\")\n\u001b[0;32m   1323\u001b[0m             dists = cdist(X / length_scale, Y / length_scale,\n\u001b[1;32m-> 1324\u001b[1;33m                           metric='euclidean')\n\u001b[0m\u001b[0;32m   1325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnu\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, p, V, VI, w)\u001b[0m\n\u001b[0;32m   2204\u001b[0m             \u001b[0mXA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2205\u001b[0m             \u001b[0mXB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2206\u001b[1;33m             \u001b[0mcdist_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2207\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lgb_evaluate(min_data_in_leaf,\n",
    "                     bagging_fraction,\n",
    "                     feature_fraction,\n",
    "                     num_leaves,\n",
    "                     lambda_l2,\n",
    "                     ):\n",
    "\n",
    "        params['min_data_in_leaf'] = int(min_data_in_leaf)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['num_leaves'] = int(num_leaves)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cv_result = lgb.cv(nfold=5,params=params, metrics='binary_logloss',stratified=False,train_set=lgbtrain,\n",
    "               num_boost_round=num_rounds,seed=random_state, callbacks=[lgb.callback.early_stopping(50)])\n",
    "        return -(cv_result.get('binary_logloss-mean')[-1])\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "        X = train[strong]\n",
    "        _X = lgb.Dataset(X, label=y)\n",
    "\n",
    "        return _X\n",
    "\n",
    "\n",
    "lgbtrain = prepare_data()\n",
    "\n",
    "num_rounds = 200\n",
    "random_state = 0\n",
    "num_iter = 1000\n",
    "init_points = 5\n",
    "params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'binary_logloss',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "lgbBO = BayesianOptimization(lgb_evaluate, {'min_data_in_leaf': (4, 100),\n",
    "                                                'bagging_fraction': (0.5, 1),\n",
    "                                                'feature_fraction': (0.5, 1),\n",
    "                                                'num_leaves': (4, 100),\n",
    "                                                'lambda_l2': (0, 5),\n",
    "                                                })\n",
    "\n",
    "lgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params4 = {'bagging_fraction': 0.9458564289234204,\n",
    " 'feature_fraction': 0.5004666960515116,\n",
    " 'lambda_l2': 0.022577930769472343,\n",
    " 'min_data_in_leaf': 99,\n",
    " 'num_leaves': 13}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b672e5f00e641568adcdb0ec534ff8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oof log_loss: 0.1628696551515784\n",
      "oof roc_auc: 0.9119577244555006\n",
      "oof f1_score: 0.5340878469415252\n",
      "train log_loss: 0.15074728123441578\n",
      "train roc_auc: 0.9343313059337881\n",
      "train f1_score: 0.5766009186706296\n"
     ]
    }
   ],
   "source": [
    "params5 = {'bagging_fraction': 0.9458564289234204,\n",
    " 'feature_fraction': 0.5004666960515116,\n",
    " 'lambda_l2': 0.022577930769472343,\n",
    " 'min_data_in_leaf': 99,\n",
    " 'num_leaves': 13}\n",
    "model = LGBWrapper(params5)\n",
    "cvpred = get_oof_pred(model, train, y, KFold(n_splits=5, shuffle=True, random_state=0))\n",
    "model.fit(train, y)\n",
    "pred = model.predict(train)\n",
    "print('oof log_loss: {}'.format(log_loss(y, cvpred)))\n",
    "print('oof roc_auc: {}'.format(roc_auc_score(y, cvpred)))\n",
    "\n",
    "def minus_f_score(cutoff):\n",
    "    if (cutoff < 0) or (cutoff > 1):\n",
    "        return np.inf\n",
    "    else:\n",
    "        return - 1* f1_score(y, 1 * (cvpred > cutoff))   \n",
    "    \n",
    "cutoff_null = [0]\n",
    "cut_f_min = fmin(minus_f_score, cutoff_null, disp=False)\n",
    "cut = cut_f_min[0]\n",
    "print('oof f1_score: {}'.format(f1_score(y, 1 * (cvpred > cut))))\n",
    "\n",
    "print('train log_loss: {}'.format(log_loss(y, pred)))\n",
    "print('train roc_auc: {}'.format(roc_auc_score(y, pred)))\n",
    "print('train f1_score: {}'.format(f1_score(y, 1 * (pred > cut))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD 2-nd MODEL FROM WNS_starter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvpred_lgb2 = pd.read_csv('oof.csv').is_promoted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvpred_lgb, cvpred_lgb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutoff selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minus_f_score(m):\n",
    "    cutoff, w1 = m\n",
    "    cvpreds = w1*cvpred_lgb +  (1-w1)*cvpred_lgb2\n",
    "    if (cutoff < 0) or (cutoff > 1):\n",
    "        return np.inf\n",
    "    elif (w1 < 0) or (w1 > 1):\n",
    "        return np.inf\n",
    "    else:\n",
    "        return - 1* f1_score(y, 1 * (cvpreds > cutoff))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.537037\n",
      "         Iterations: 49\n",
      "         Function evaluations: 108\n",
      "cutoff:  0.26892412357610007 0.750349262739415\n"
     ]
    }
   ],
   "source": [
    "cutoff_null = [0, 0.5]\n",
    "cut_f_min = fmin(minus_f_score, cutoff_null)\n",
    "cut, w = cut_f_min\n",
    "print('cutoff: ', cut, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.537037037037037\n",
      "recall_score: 0.42245072836332476\n",
      "precision_score: 0.7369207772795217\n"
     ]
    }
   ],
   "source": [
    "print('f1_score: {}'.format(f1_score(y, 1 * (w*cvpred_lgb +  (1-w)*cvpred_lgb2 > cut))))\n",
    "print('recall_score: {}'.format(recall_score(y, 1 * (w*cvpred_lgb +  (1-w)*cvpred_lgb2 > cut))))\n",
    "print('precision_score: {}'.format(precision_score(y, 1 * (w*cvpred_lgb +  (1-w)*cvpred_lgb2 > cut))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_strong2.csv')\n",
    "test = pd.read_csv('test_strong2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params4 = {'bagging_fraction': 0.9458564289234204,\n",
    " 'feature_fraction': 0.5004666960515116,\n",
    " 'lambda_l2': 0.022577930769472343,\n",
    " 'min_data_in_leaf': 99,\n",
    " 'num_leaves': 13}\n",
    "model = LGBWrapper(params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161eaaf16ea04a3bad5c68f8a5a5d89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_oof_cv(model, X, y, test, folds):    \n",
    "    pred = np.zeros(test.shape[0])\n",
    "    for tr, te in tqdm_notebook(folds.split(X, y)):\n",
    "        X_tr, X_te = X.loc[tr], X.loc[te]\n",
    "        y_tr, y_te = y[tr], y[te]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        pred += model.predict(test)\n",
    "    pred /= folds.get_n_splits()\n",
    "    return  pred\n",
    "\n",
    "model = MWrapper(RandomForestClassifier(max_depth=7, max_features=0.5))\n",
    "pred_cv_rf = get_oof_cv(model, train,y, test, KFold(n_splits=5, shuffle=True, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cv_lgb2 = pd.read_csv('sub2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = w*pred_cv_lgb + (1-w)*pred_cv_lgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['is_promoted'] = 1 * (pred > cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('mix_opt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04355044699872286"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['is_promoted'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
